#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ª–æ–≥–æ–≤ –∏–∑ Google Cloud —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
"""

import os
import json
import re
import subprocess
import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º UTF-8 –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É
os.environ['PYTHONIOENCODING'] = 'utf-8'

def install_required_packages():
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç"""
    try:
        import ftfy
        import unidecode
        import charset_normalizer
    except ImportError:
        print("–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π...")
        subprocess.run([sys.executable, "-m", "pip", "install", "ftfy", "unidecode", "charset-normalizer"], check=True)
        print("–ü–∞–∫–µ—Ç—ã —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!")

def fix_cyrillic_encoding(text):
    """
    –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
    """
    if not text:
        return text
    
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
        import ftfy
        import charset_normalizer
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º ftfy - –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç mojibake
        fixed_text = ftfy.fix_text(text)
        
        # –ï—Å–ª–∏ ftfy –Ω–µ –ø–æ–º–æ–≥, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –º–µ—Ç–æ–¥—ã
        if fixed_text == text and ('?' in text or '???' in text):
            # –ü—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ–∞–ª—å–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É
            detected = charset_normalizer.detect(text.encode('utf-8', errors='ignore'))
            if detected and detected.get('confidence', 0) > 0.7:
                encoding = detected['encoding']
                try:
                    # –ü–µ—Ä–µ–∫–æ–¥–∏—Ä—É–µ–º
                    fixed_text = text.encode('latin-1').decode(encoding, errors='ignore')
                except:
                    pass
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ Unicode escape –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        if '\\u04' in fixed_text or '\\u05' in fixed_text:  # –ö–∏—Ä–∏–ª–ª–∏—Ü–∞
            try:
                import codecs
                fixed_text = codecs.decode(fixed_text, 'unicode_escape')
            except:
                pass
        
        return fixed_text
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏: {e}")
        return text

def get_logs_via_gcloud():
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ª–æ–≥–∏ —á–µ—Ä–µ–∑ gcloud CLI —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏
    """
    print("–ò—Å–ø–æ–ª—å–∑—É–µ–º gcloud CLI...")
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
    cmd = [
        "gcloud", "logging", "read",
        'resource.type="cloud_run_revision" resource.labels.service_name="auraflora-bot"',
        "--limit=2000",
        "--format=json"
    ]
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–º–∞–Ω–¥—É –ë–ï–ó shell=True –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace',
            check=True
        )
        
        if result.returncode != 0:
            print(f"–û—à–∏–±–∫–∞ gcloud: {result.stderr}")
            return None, False
        
        # –ü–∞—Ä—Å–∏–º JSON
        logs_data = json.loads(result.stdout)
        print(f"–ü–æ–ª—É—á–µ–Ω–æ {len(logs_data)} –∑–∞–ø–∏—Å–µ–π —á–µ—Ä–µ–∑ gcloud CLI")
        return logs_data, True
        
    except subprocess.CalledProcessError as e:
        print(f"–û—à–∏–±–∫–∞ –∫–æ–º–∞–Ω–¥—ã gcloud: {e}")
        print(f"stderr: {e.stderr}")
        return None, False
    except json.JSONDecodeError as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        return None, False
    except Exception as e:
        print(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        return None, False

def extract_and_fix_logs(logs_data):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∫–æ–¥–∏—Ä–æ–≤–∫—É –ª–æ–≥–æ–≤
    """
    fixed_logs = []
    ai_responses = []
    
    print("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –ª–æ–≥–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª—è—é –∫–æ–¥–∏—Ä–æ–≤–∫—É...")
    
    for i, log_entry in enumerate(logs_data):
        if i % 100 == 0 and i > 0:
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i} –∑–∞–ø–∏—Å–µ–π")
        
        timestamp = log_entry.get('timestamp', '')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –ª–æ–≥–∞
        log_text = ""
        if 'textPayload' in log_entry and log_entry['textPayload']:
            log_text = str(log_entry['textPayload'])
        elif 'jsonPayload' in log_entry and log_entry['jsonPayload']:
            log_text = json.dumps(log_entry['jsonPayload'], ensure_ascii=False, indent=2)
        
        if not log_text:
            continue
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
        fixed_text = fix_cyrillic_encoding(log_text)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
        fixed_logs.append({
            'timestamp': timestamp,
            'text': fixed_text,
            'original': log_text
        })
        
        # –ò—â–µ–º AI –æ—Ç–≤–µ—Ç—ã
        if any(keyword in fixed_text for keyword in ['AI response:', '[AI_DEBUG]', 'PARSE_RESPONSE', '"text":']):
            # –ò–∑–≤–ª–µ–∫–∞–µ–º AI –æ—Ç–≤–µ—Ç
            ai_text = extract_ai_response(fixed_text)
            if ai_text:
                ai_responses.append({
                    'timestamp': timestamp,
                    'response': ai_text,
                    'original': log_text
                })
    
    return fixed_logs, ai_responses

def extract_ai_response(text):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç AI –æ—Ç–≤–µ—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ª–æ–≥–∞
    """
    # –ò—â–µ–º –ø—Ä—è–º–æ–π AI response
    ai_match = re.search(r'AI response:\s*(.+)', text)
    if ai_match:
        return ai_match.group(1).strip()
    
    # –ò—â–µ–º JSON —Å —Ç–µ–∫—Å—Ç–æ–º
    json_match = re.search(r'"text":\s*"([^"]*)"', text)
    if json_match:
        return json_match.group(1).strip()
    
    # –ò—â–µ–º –¥—Ä—É–≥–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    if '[AI_DEBUG]' in text:
        debug_match = re.search(r'\[AI_DEBUG\]\s*(.+)', text)
        if debug_match:
            return debug_match.group(1).strip()
    
    return None

def save_logs(fixed_logs, ai_responses):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ª–æ–≥–∏ –≤ —Ñ–∞–π–ª—ã
    """
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    logs_dir = Path("fixed_logs")
    logs_dir.mkdir(exist_ok=True)
    
    # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    now = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –ª–æ–≥–∏
    all_logs_file = logs_dir / f"all_logs_fixed_{now}.json"
    with open(all_logs_file, 'w', encoding='utf-8') as f:
        json.dump(fixed_logs, f, ensure_ascii=False, indent=2)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ AI –æ—Ç–≤–µ—Ç—ã
    ai_logs_file = logs_dir / f"ai_responses_fixed_{now}.json"
    with open(ai_logs_file, 'w', encoding='utf-8') as f:
        json.dump(ai_responses, f, ensure_ascii=False, indent=2)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç AI –æ—Ç–≤–µ—Ç–æ–≤
    ai_readable_file = logs_dir / f"ai_responses_readable_{now}.txt"
    with open(ai_readable_file, 'w', encoding='utf-8') as f:
        f.write("AI –û–¢–í–ï–¢–´ –° –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ô –ö–ò–†–ò–õ–õ–ò–¶–ï–ô\n")
        f.write("=" * 50 + "\n\n")
        
        for i, ai_entry in enumerate(ai_responses[-50:]):  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 50
            f.write(f"{i+1}. [{ai_entry['timestamp']}]\n")
            f.write(f"AI: {ai_entry['response']}\n")
            f.write("-" * 50 + "\n\n")
    
    print(f"\n–õ–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print(f"  - –í—Å–µ –ª–æ–≥–∏: {all_logs_file}")
    print(f"  - AI –æ—Ç–≤–µ—Ç—ã (JSON): {ai_logs_file}")
    print(f"  - AI –æ—Ç–≤–µ—Ç—ã (—á–∏—Ç–∞–µ–º—ã–π): {ai_readable_file}")
    
    return ai_readable_file

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
    """
    print("–°–ö–†–ò–ü–¢ –ü–û–õ–£–ß–ï–ù–ò–Ø –õ–û–ì–û–í –° –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï–ú –ö–ò–†–ò–õ–õ–ò–¶–´")
    print("=" * 60)
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–∞–∫–µ—Ç—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    install_required_packages()
    
    # –ü–æ–ª—É—á–∞–µ–º –ª–æ–≥–∏ —á–µ—Ä–µ–∑ CLI
    logs_data, success = get_logs_via_gcloud()
    
    if not success or not logs_data:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ª–æ–≥–∏!")
        return
    
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(logs_data)} –∑–∞–ø–∏—Å–µ–π –ª–æ–≥–æ–≤")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ª–æ–≥–∏
    fixed_logs, ai_responses = extract_and_fix_logs(logs_data)
    
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(fixed_logs)} –∑–∞–ø–∏—Å–µ–π")
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(ai_responses)} AI –æ—Ç–≤–µ—Ç–æ–≤")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    readable_file = save_logs(fixed_logs, ai_responses)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
    if ai_responses:
        print(f"\nüìù –ü–û–°–õ–ï–î–ù–ò–ï 5 AI –û–¢–í–ï–¢–û–í:")
        print("-" * 40)
        for i, ai_entry in enumerate(ai_responses[-5:]):
            print(f"{i+1}. {ai_entry['response'][:100]}...")
    
    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª: {readable_file}")

if __name__ == "__main__":
    main() 